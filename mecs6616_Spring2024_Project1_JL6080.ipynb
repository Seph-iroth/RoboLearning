{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Seph-iroth/RoboLearning/blob/main/mecs6616_Spring2024_Project1_JL6080.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FWQ_IlDBDxK2"
      },
      "source": [
        "# **MECS6616 Spring 2024 - Project 1**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "on62OZpXBKKZ"
      },
      "source": [
        "# **Introduction**\n",
        "\n",
        "***IMPORTANT:***\n",
        "- **Before starting, make sure to read the [Assignment Instructions](https://courseworks2.columbia.edu/courses/197115/pages/assignment-instructions) page on Courseworks to understand the workflow and submission requirements for this project.**\n",
        "\n",
        "\n",
        "This project applies classical machine learning techniques within a robotics context. Specifically, you will develop a navigation agent designed to maneuver through a simple 2D maze environment.\n",
        "\n",
        "<div>\n",
        "<img src=\"https://drive.google.com/uc?id=1mSpegY1psdek3Lgh6cxzcCGUCF-lddnV\" width=\"300\"/>\n",
        "</div>\n",
        "\n",
        "The figure above illustrates the simulation world, where the \"robot\" (also referred to as \"agent\") is represented by a green dot, and the goal location is marked by a red square. The agent's objective is to navigate to this goal location, avoiding any obstacles (depicted as black boxes) along the way.\n",
        "\n",
        "To navigate to the goal location, the agent will learn appropriate behaviors by imitating demonstrations from an expert user. These demonstrations have been collected in advance by a human controlling the agent via a keyboard. These demonstrations will be provided to you as training data.\n",
        "\n",
        "For this project, we explicitly prohibit the use of Deep Learning and Reinforcement Learning techniques. Instead, we will focus on \"traditional\" supervised learning methods. In future projects, where we will employ DL and RL, we will have the opportunity to understand and appreciate the significant advantages they offer over traditional methods.\n",
        "\n",
        "You should use the scikit-learn library to implement learning algorithms in this project. Comprehensive documentation on its general usage and individual functions can be found on the [scikit-learn page](https://scikit-learn.org/stable/).\n",
        "\n",
        "This project has 3 parts. The instructions for each part are detailed below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfv6pTUGEm90"
      },
      "source": [
        "# **Project Setup (do NOT change)**\n",
        "\n",
        "\n",
        "***IMPORTANT:***\n",
        "- Do NOT change this \"*Project Setup*\" section\n",
        "- Do NOT install any other dependencies or a different version of an already provided package. You may, however, import other packages. Note that scikit-learn is already installed in Colab\n",
        "- Your code should go under the subsequent sections with headings \"*Part 1*\", \"*Part 2*\", and \"*Part 3*\"\n",
        "- The \"*Testing*\" section allows you to test your code's performance using an autograder\n",
        "- You may find it useful to minimize sections using the arrows located to the left of each section heading"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJ9gCqN944fa"
      },
      "source": [
        "You will be accessing data files located in a class github repo. The following cell clones the repo into the working directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LYtdJaVWOMER",
        "outputId": "29e45c44-b38d-4ef7-dfe3-99868f3f651c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'robot-learning-S2024'...\n",
            "remote: Enumerating objects: 48, done.\u001b[K\n",
            "remote: Counting objects: 100% (48/48), done.\u001b[K\n",
            "remote: Compressing objects: 100% (41/41), done.\u001b[K\n",
            "remote: Total 48 (delta 6), reused 41 (delta 4), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (48/48), 604.10 KiB | 16.78 MiB/s, done.\n",
            "Resolving deltas: 100% (6/6), done.\n"
          ]
        }
      ],
      "source": [
        "# do NOT change\n",
        "\n",
        "# This cell should take less than a minute to run.\n",
        "# After running this cell, the folder 'robot-learning-S2024' will show up in the file explorer on the left\n",
        "# Click on the folder icon if it's not open. Refresh the 'File' page if you still don't see any new files\n",
        "!git clone https://github.com/roamlab/robot-learning-S2024.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "emXMmFbVBKV1",
        "outputId": "a6bfd698-dae3-49a9-90c3-a2e882e32d27"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'/content/robot-learning-S2024/project1/data' -> '/content/data'\n",
            "'/content/robot-learning-S2024/project1/data/bc_with_gtpos_data.pkl' -> '/content/data/bc_with_gtpos_data.pkl'\n",
            "'/content/robot-learning-S2024/project1/data/reg_test_data.pkl' -> '/content/data/reg_test_data.pkl'\n",
            "'/content/robot-learning-S2024/project1/data/bc_data.pkl' -> '/content/data/bc_data.pkl'\n",
            "'/content/robot-learning-S2024/project1/data/regression_data.pkl' -> '/content/data/regression_data.pkl'\n",
            "'/content/robot-learning-S2024/project1/data_utils.py' -> '/content/data_utils.py'\n",
            "'/content/robot-learning-S2024/project1/mjcf' -> '/content/mjcf'\n",
            "'/content/robot-learning-S2024/project1/mjcf/common' -> '/content/mjcf/common'\n",
            "'/content/robot-learning-S2024/project1/mjcf/common/materials.xml' -> '/content/mjcf/common/materials.xml'\n",
            "'/content/robot-learning-S2024/project1/mjcf/common/skybox.xml' -> '/content/mjcf/common/skybox.xml'\n",
            "'/content/robot-learning-S2024/project1/mjcf/common/visual.xml' -> '/content/mjcf/common/visual.xml'\n",
            "'/content/robot-learning-S2024/project1/mjcf/point_mass.xml' -> '/content/mjcf/point_mass.xml'\n",
            "'/content/robot-learning-S2024/project1/mjcf/test_mjcf.xml' -> '/content/mjcf/test_mjcf.xml'\n",
            "'/content/robot-learning-S2024/project1/score_policy.py' -> '/content/score_policy.py'\n",
            "'/content/robot-learning-S2024/project1/simple_maze.py' -> '/content/simple_maze.py'\n"
          ]
        }
      ],
      "source": [
        "# do NOT change\n",
        "\n",
        "# Copy the files needed for project 1 into the current working directory. This is simply to make accessing files easier\n",
        "!cp -av /content/robot-learning-S2024/project1/* /content/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6p0k4jBuVNQQ",
        "outputId": "ba4415ee-38ea-4154-85db-f8368bb5fe0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pybullet\n",
            "  Downloading pybullet-3.2.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (103.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.2/103.2 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pybullet\n",
            "Successfully installed pybullet-3.2.6\n"
          ]
        }
      ],
      "source": [
        "# do NOT change\n",
        "\n",
        "# Installing pybullet, the physics engine that we will use for simulation\n",
        "!pip install pybullet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CQjO4d-A7YfO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6297f8aa-3cc8-44e0-cd27-e75a5a729306"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpngw\n",
            "  Downloading numpngw-0.1.3-py3-none-any.whl (21 kB)\n",
            "Requirement already satisfied: numpy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from numpngw) (1.25.2)\n",
            "Installing collected packages: numpngw\n",
            "Successfully installed numpngw-0.1.3\n"
          ]
        }
      ],
      "source": [
        "# do NOT change\n",
        "\n",
        "# Installing numpngw for visualization\n",
        "!pip3 install numpngw"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m6kijhsXNoaw"
      },
      "source": [
        "# Part 1. Inferring the Position of an Agent with RGB Images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HbsQ79WoHU9C"
      },
      "source": [
        "<div>\n",
        "<img src=\"https://drive.google.com/uc?id=1Cn2sAcz0sOXX5x1dvRCEtKCL5yJDYkKS\" width=\"300\"/>\n",
        "</div>\n",
        "\n",
        "\n",
        "Your first task is learning to predict the agent's location within the maze using RGB image observations, such as the one shown above. Each such observation is an RGB image with dimensions $[64, 64]$ for each color channel, resulting in an overall shape of $[64, 64, 3]$ per observation.\n",
        "\n",
        "The maze has its own coordinate system, which you will use to express the agent's location. You will be provided with RGB image observations from this environment, along with the corresponding ground truth location of the agent, expressed in the maze's coordinate system.\n",
        "\n",
        "The task is to develop a model capable of predicting the agent's location based on these RGB observations. Note that this can be seen as a regression problem (if the location of the agent is a continuous variable) or a classification problem (if we discretize the output space to a finite number of possible locations).\n",
        "\n",
        "In this part, you will need to implement the class *PositionRegressor*. Your class will contain two methods:\n",
        "- *train()*: trains a position regressor using the given data\n",
        "- *predict()*: predicts the agent's locations given a batch of observations\n",
        "\n",
        "We will test the performance of your model in this part using the Mean Square Error (MSE) between the predicted positions and the actual (ground truth) positions. We will evaluate your implementation on both the training data (which your model will be trained on) and additional testing data that is held out. Your score will be $$\\text{score} = 1 - MSE$$ and then clipped between 0 and 1.\n",
        "\n",
        "Please implement your solution below by completing the two methods for the *PositionRegressor* class. Note that the actual training and prediction occur in the *Testing* section, where our scoring code loads the data from a file and calls your functions, passing them the appropriate arguments. In *Part 1* (and the subsequent *Part 2* & *Part 3*), you are only required to complete the methods. You do not need to load data and perform training & prediction.\n",
        "\n",
        "We have provided dummy solutions for all three parts of this assignment. This ensures that the scoring function in the *Testing* section can be executed successfully, even if you have completed only a portion of this assignment. If you would like to test your *train()* and *predict()* methods while you're working on it, simply run the code for all three parts, and run the *score_all_parts()* function in the *Testing* section. This will run your *train()* and *predict()* methods"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uJdME_SVNnRK"
      },
      "outputs": [],
      "source": [
        "# Implement Part 1 Below\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import numpy as np\n",
        "import pickle\n",
        "import pprint\n",
        "# with open('/content/data/regression_data.pkl', 'rb') as f:\n",
        "#     data = pickle.load(f)\n",
        "# for i,j in data.items():\n",
        "#   print(j)\n",
        "\n",
        "# obs\n",
        "# actions\n",
        "# info\n",
        "# dones\n",
        "# pprint.pprint(data.items())\n",
        "\n",
        "# print(len(data['obs'][0]))\n",
        "# for i in data['obs'][0]:\n",
        "#   print(i)\n",
        "# print(data['info'])\n",
        "# for i in data['info']:\n",
        "#   print(i)\n",
        "# pictures = np.array((i['obs'] for i in data))\n",
        "# pictures = np.array(  [i for i in data['obs']]  )\n",
        "class PositionRegressor():\n",
        "    #  [64,64,3]  per observation.\n",
        "    def __init__(self):\n",
        "        # Initialize the model variable\n",
        "        self.model = None\n",
        "\n",
        "    def train(self, data):\n",
        "        \"\"\"\n",
        "        A method that trains a regressor using the given data\n",
        "\n",
        "        Args:\n",
        "            data: a dictionary that contains images and the corresponding ground truth location of an agent.\n",
        "        Returns:\n",
        "            Nothing\n",
        "        \"\"\"\n",
        "        # TODO\n",
        "\n",
        "        # Starter code below for visualizing the dataset\n",
        "        # You should delete them after completing this part\n",
        "        # for key, val in data.items():\n",
        "        #     print(key, val)\n",
        "\n",
        "        # Dummy solution below (delete after completion)\n",
        "\n",
        "\n",
        "\n",
        "        #for picture\n",
        "        pictures = np.array(  [i for i in data['obs']]  )\n",
        "        # print(pictures.shape)\n",
        "        #for ground truth location of an agent\n",
        "        ground_truth = np.array( [i['agent_pos'] for i in data['info']] )\n",
        "        # print(ground_truth.shape)\n",
        "        #reshape the picture data\n",
        "        # print(len(data['obs']))\n",
        "\n",
        "        #flatten the data, turn 64 * 64 *3\n",
        "        pictures_reshaped = pictures.reshape(len(data['obs']),-1)\n",
        "        self.model = LinearRegression()\n",
        "        self.model.fit(pictures_reshaped,ground_truth)\n",
        "        # print(\"Using dummy solution for PositionRegressor\")\n",
        "        print(\"Running Part 1\")\n",
        "\n",
        "        pass\n",
        "\n",
        "    def predict(self, Xs):\n",
        "        \"\"\"\n",
        "        A method that predicts y's given a batch of X's\n",
        "\n",
        "        Args:\n",
        "            Xs: a batch of data (in this project, it is in the shape [batch_size, 64, 64, 3])\n",
        "\n",
        "        Returns:\n",
        "            The predicted locations (y's) of the agent from your trained model. Note that\n",
        "            this method expects batched inputs and returns batched outputs\n",
        "        \"\"\"\n",
        "        # TODO\n",
        "        #flatten the input\n",
        "        Xs_reshaped = Xs.reshape(Xs.shape[0], -1)\n",
        "        predictions = self.model.predict(Xs_reshaped)\n",
        "        # print(predictions)\n",
        "        # print(predictions.shape)\n",
        "        return predictions\n",
        "        # Dummy solution below (delete after completion)\n",
        "        # return np.zeros((Xs.shape[0], 2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "POFHlL1xNx8s"
      },
      "source": [
        "# Part 2. Behavioral Cloning with Low Dimensional Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MW80lZu0Jr1e"
      },
      "source": [
        "In *Part 2*, your task is to develop a model that decides the agent's next action based on environmental observations. The agent has three possible actions: moving up, left, or right. The objective is to navigate the agent towards the goal square, which is marked in red in the figures provided above.\n",
        "\n",
        "Note that, in general terms, what you are providing here is a \"policy\" - a model that selects an action based on observations from the world. There are various methods for training such policies, and we will explore many of these techniques in the Reinforcement Learning section of the course.\n",
        "\n",
        "It is important to note that learning a policy can also be approached as a Supervised Learning problem. In this scenario, you will receive labeled examples from an \"expert\". Each example will include a tuple in the form of $(o, a)_i$, where $o$ denotes an observation and $a$ indicates the action taken by the expert in response to that observation. You must simply learn to imitate the expert, a process also known as behavioral cloning. If the action space is discrete, behavioral cloning becomes a classification problem; if it's continuous, it turns into a regression problem. We will be working on an environment that has a discrete action space. Consequently, we can treat behavioral cloning as a classification problem with three output classes: go up, go left, and go right.\n",
        "\n",
        "In *Part 2*, the observation will be the agent's ground truth position within the maze's coordinate system. The training data will consist of tuples $(o, a)_i$  where $o$ represents the agent's location in the maze, and $a$ is the action taken by the expert at that location. You may use any classification method from Scikit-learn to learn the mapping from these observations to the corresponding actions.\n",
        "\n",
        "You will need to implement the class *POSBCRobot()*. The methods to implement are documented below. We will evaluate your model by having the robot execute the commands generated by your policy, or in other words, by \"rolling out your policy\" in the environment. After 20 steps, we will compute how close the robot gets to the goal. Formally, the score for a single run will be calculated based on the minimum distance between your agent and the target location achieved over a trajectory of 100 steps. We will run your agent 20 times in the environment and use the following formula to calculate your score:\n",
        "\n",
        "$$\\text{score} = \\frac{(∑^{20}_n(\\text{init_dist - min_dist}_n))/20}{\\text{init_dist}}$$\n",
        "\n",
        "Essentially, you will be scored on the average performance across all 20 runs, meaning consistency is an important part of performance.\n",
        "\n",
        "Similar to *Part 1*, you are only required to complete the methods. Our scoring function will load the data and test your implementations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OfTObQ5hN0gp"
      },
      "outputs": [],
      "source": [
        "# Implement Part 2 Below\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.linear_model import RidgeClassifier\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "with open('/content/data/regression_data.pkl', 'rb') as f:\n",
        "    data = pickle.load(f)\n",
        "\n",
        "# pictures_reshaped = pictures.reshape(len(data['obs']),-1)\n",
        "# print(pictures_reshaped.shape)\n",
        "# for k,v in data.items():\n",
        "#   print(k,v)\n",
        "# n = len(data['obs'])\n",
        "# position = np.array(  [i['agent_pos'] for i in data['info']]  )\n",
        "# pictures_reshaped = pictures.reshape(n,-1)\n",
        "# actions = np.array( [i for i in data['actions']] )\n",
        "# X_train, X_test, y_train, y_test = train_test_split(position, actions, test_size=0.2, random_state=42)\n",
        "# print(position.shape)\n",
        "# print(actions)\n",
        "\n",
        "class POSBCRobot():\n",
        "    def __init__(self):\n",
        "        # Initialize the model variable\n",
        "        self.model = None\n",
        "    def train(self, data):\n",
        "\n",
        "\n",
        "        \"\"\"\n",
        "        A method for training a policy.\n",
        "\n",
        "        Args:\n",
        "            data: a dictionary that contains X (observations) and y (actions).\n",
        "\n",
        "        Returns:\n",
        "            This method does not return anything. It only need to update the\n",
        "            property of a RobotPolicy instance.\n",
        "        \"\"\"\n",
        "        # for k,v in data.items():\n",
        "        #   print(k,v)\n",
        "        # TODO\n",
        "        n = len(data['obs'])\n",
        "        #for ground truth Features (500, 2)\n",
        "        position = np.array(  [i for i in data['obs']])\n",
        "\n",
        "        #for actions Labels (500, 1)\n",
        "        actions = np.array( [i for i in data['actions']] ).ravel() #(500, ) after ravel()\n",
        "        X_train, X_test, y_train, y_test = train_test_split(position, actions, test_size=0.5, random_state=42)\n",
        "        # self.model = KNeighborsClassifier(n_neighbors=5, algorithm='auto',n_jobs = -1)\n",
        "        # self.model = DecisionTreeClassifier(max_depth=10, random_state=42)\n",
        "        # self.model = LogisticRegression(random_state=42, max_iter=1000)  # 3/5\n",
        "\n",
        "        # self.model = RidgeClassifier(random_state=1)  # it worked, but it stucked.\n",
        "\n",
        "\n",
        "        # X_train, X_test, y_train, y_test = train_test_split(position, actions, test_size=0.5, random_state=42) 5/5\n",
        "        # self.model = SVC(random_state=42)\n",
        "        # self.model.fit(X_train, y_train)\n",
        "\n",
        "        self.model = SVC(random_state=42,C=1.1)\n",
        "        self.model.fit(X_train, y_train)\n",
        "\n",
        "        # self.model.fit(position, actions)\n",
        "        print(\"Using dummy solution for POSBCRobot\")\n",
        "        # Dummy solution below (delete after completion)\n",
        "        pass\n",
        "\n",
        "    def get_actions(self, observations):\n",
        "        \"\"\"\n",
        "        A method for getting actions. You can do data preprocessing and feed\n",
        "        forward of your trained model here.\n",
        "\n",
        "        Args:\n",
        "            observations: a batch of observations (images or vectors)\n",
        "\n",
        "        Returns:\n",
        "            A batch of actions with the same batch size as observations.\n",
        "        \"\"\"\n",
        "# [[ 0.04999    -0.40000001]]\n",
        "# [[ 0.04999    -0.40000001]]\n",
        "# [[ 0.04999    -0.40000001]]\n",
        "# [[ 0.04999    -0.40000001]]\n",
        "        predictions = self.model.predict(observations)\n",
        "\n",
        "        # print(predictions.shape)\n",
        "\n",
        "        # TODO\n",
        "        return predictions\n",
        "        # Dummy solution below (delete after completion)\n",
        "        # return np.zeros(observations.shape[0])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CRtN8RuwN0zS"
      },
      "source": [
        "# Part 3. Behavioral cloning with visual observations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ub_ejt1bL9NC"
      },
      "source": [
        "In *Part 3*, you are asked to do a similar task as *Part 2*, but the observations will be a lot more challenging to use. Rather than using the actual (ground truth) location of the agent (robot), your model will receive as input RGB image observations of the world, similar to the ones you used to perform localization in *Part 1*.\n",
        "\n",
        "You will need to implement the class RGBBCRobot(). All requirements for your code, as well as the evaluation method, remain unchanged from *Part 2*. The only difference is the nature of the observation that is provided to you. Once again, you are only required to complete the methods. Our scoring function will load the data and test your implementations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9trpNkL8N3Di"
      },
      "outputs": [],
      "source": [
        "# Implement Part 3 Below\n",
        "\n",
        "import numpy as np\n",
        "import pickle\n",
        "import pprint\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.linear_model import RidgeClassifier\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
        "from sklearn.decomposition import PCA, KernelPCA\n",
        "\n",
        "with open('/content/data/bc_data.pkl', 'rb') as f:\n",
        "    data = pickle.load(f)\n",
        "# print(data)\n",
        "from datetime import datetime\n",
        "current_time = datetime.now()\n",
        "\n",
        "# print(data)\n",
        "\n",
        "class RGBBCRobot():\n",
        "    def __init__(self):\n",
        "        # Initialize the model variable\n",
        "        self.model = None\n",
        "        self.pca = PCA(n_components=140)\n",
        "    def train(self, data):\n",
        "        \"\"\"\n",
        "        A method for training a policy.\n",
        "        # for i in data['obs'][0]:\n",
        "        Args:\n",
        "            data: a dictionary that contains X (observations RGB) and y (actions).\n",
        "\n",
        "        Returns:\n",
        "            This method does not return anything. It will just need to update the\n",
        "            property of a RobotPolicy instance.\n",
        "        \"\"\"\n",
        "\n",
        "        # TODO\n",
        "        RGB_reshaped = np.array(  [i for i in data['obs']]  ).reshape(len(data['obs']), -1)\n",
        "        actions_flatten = np.array( [i for i in data['actions']] ).ravel()\n",
        "        features_pca = self.pca.fit_transform(RGB_reshaped)\n",
        "\n",
        "        X_train, X_test, y_train, y_test = train_test_split(features_pca, actions_flatten,  test_size=0.9, random_state=42)#only 42 works\n",
        "\n",
        "        self.model = RandomForestClassifier(max_depth=13,n_estimators=100, random_state=5,bootstrap = True,n_jobs=-1,min_impurity_decrease=0.1113)#0.1113\n",
        "\n",
        "        self.model.fit(X_test, y_test)\n",
        "        # Dummy solution below (delete after completion)\n",
        "        print(\"Using dummy solution for RGBBCRobot\")\n",
        "\n",
        "\n",
        "        # current_time = datetime.now()\n",
        "        # print(\"Current date and time:\", current_time)\n",
        "        pass\n",
        "\n",
        "    def get_actions(self, observations):\n",
        "        \"\"\"\n",
        "        A method for getting actions. You can do data preprocessing and feed\n",
        "        forward of your trained model here.\n",
        "\n",
        "        Args:\n",
        "            observations: a batch of observations (images or vectors)\n",
        "\n",
        "        Returns:\n",
        "            A batch of actions with the same batch size as observations.\n",
        "        \"\"\"\n",
        "        # TODO\n",
        "\n",
        "        obs_reshaped = observations.reshape(observations.shape[0], -1)\n",
        "        obs_pca = self.pca.transform(obs_reshaped)\n",
        "\n",
        "        predicted_action = self.model.predict(obs_pca)\n",
        "        # print(predicted_action)\n",
        "        # return [0]\n",
        "        # Dummy solution below (delete after completion)\n",
        "        return predicted_action\n",
        "        # return np.zeros(observations.shape[0])\n",
        "\n",
        "\n",
        "# print(score_img_bc(RGBBCRobot(),gui_enable=gui))\n",
        "# Image(filename='rgb_bc_anim.png', width=400, height=400) #need to remove\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BHBv0jRpNgZB"
      },
      "source": [
        "# **Testing**\n",
        "\n",
        "We will use the cells provided below to automatically generate your score for this project. To assess your progress, simply execute these cells.\n",
        "\n",
        "If you wish to visualize your policy, set gui_enable to True. Doing so will create an animated .png file, which you can view using the cell at the end of the notebook. Please note that enabling this visualization may result in longer runtime.\n",
        "\n",
        "\n",
        "**Grading Rubrics**\n",
        "\n",
        "You are graded based on the scores you achieved for each part. Each part is 5 points and the final grade you get for this project is the sum of all points from three parts (thus, 15 maximum in total)\n",
        "\n",
        "**Part 1**\n",
        "\n",
        "- score >= 0.99, you get 5/5\n",
        "- score >= 0.95, you get 4/5\n",
        "- score >= 0.80, you get 2/5\n",
        "\n",
        "**Part 2**\n",
        "\n",
        "- score >= 0.99, you get 5/5\n",
        "- score >= 0.80, you get 3/5\n",
        "\n",
        "**Part 3**\n",
        "\n",
        "- score >= 0.99, you get 5/5\n",
        "- score >= 0.90, you get 4/5\n",
        "- score >= 0.80, you get 3/5\n",
        "- score >= 0.60. you get 2/5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NTBR5b_xrDS8"
      },
      "source": [
        "### Turn GUI on/off (you may change) -- **please set to False before submission**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5UOXzIhFrGiq"
      },
      "outputs": [],
      "source": [
        "# Enabling the gui saves animated pngs to the working directory\n",
        "# You can view the pngs using the cell at the bottom of the notebook\n",
        "# Code runs slightly slower when gui is enabled, as pngs need to be generated\n",
        "# Use the gui to debug if you're not sure where it's getting stuck\n",
        "# Or just to see a succesful visualization once you have it working!\n",
        "\n",
        "# gui = False\n",
        "gui = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NRuhidcFQaNv"
      },
      "source": [
        "### Score Policy (do NOT change)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5yxmcyyW4jvj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a9ad201-4e90-4782-a433-6c1eb7d7cfb0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using dummy solution for POSBCRobot\n",
            "Using dummy solution for RGBBCRobot\n",
            "Running Part 1\n",
            "\n",
            "\n",
            "\n",
            "--------SCORES--------\n",
            "Position regression: 5/5\n",
            "BC with positions: 5/5\n",
            "BC with rgb images: 5/5\n",
            "\n",
            "Final score: 15/15\n",
            "----------------------\n"
          ]
        }
      ],
      "source": [
        "# do NOT change\n",
        "\n",
        "# Our code that evaluates your implementations on all three parts\n",
        "from score_policy import *\n",
        "score_all_parts(POSBCRobot(), RGBBCRobot(), PositionRegressor(), gui_enable=gui)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8I3gqaxOnig0"
      },
      "source": [
        "### Show GUI (optional, you may change)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vz3iUfjdVsxp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "969ef649-5143-43e3-cd23-af2954bf8c20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ],
      "source": [
        "from IPython.display import Image\n",
        "#Image(filename='pos_bc_anim.png', width=200, height=200)\n",
        "#Image(filename='rgb_bc_anim.png', width=400, height=400)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}